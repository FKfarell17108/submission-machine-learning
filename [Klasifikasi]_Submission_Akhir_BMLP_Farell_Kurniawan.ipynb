{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Import Library**"
      ],
      "metadata": {
        "id": "fKADPWcFKlj3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pada tahap ini, saya mengimpor beberapa library Python yang dibutuhkan untuk analisis data dan pembangunan model machine learning."
      ],
      "metadata": {
        "id": "LgA3ERnVn84N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
      ],
      "metadata": {
        "id": "BlmvjLY9M4Yj"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Memuat Dataset dari Hasil Clustering**"
      ],
      "metadata": {
        "id": "f3YIEnAFKrKL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Memuat dataset hasil clustering dari file CSV ke dalam variabel DataFrame."
      ],
      "metadata": {
        "id": "Ey3ItwTen_7E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('gariskemiskinan_with_cluster.csv')\n",
        "print(\"Dataset Shape:\", df.shape)\n",
        "print(\"\\nDataset Head:\\n\", df.head())"
      ],
      "metadata": {
        "id": "GHCGNTyrM5fS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e65b8beb-5970-44d0-93c1-57cfd075b177"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Shape: (5460, 13)\n",
            "\n",
            "Dataset Head:\n",
            "   provinsi    jenis     daerah  tahun    periode        gk  jenis_encoded  \\\n",
            "0     ACEH  MAKANAN  PERKOTAAN   2015      MARET  293697.0              0   \n",
            "1     ACEH  MAKANAN  PERKOTAAN   2015  SEPTEMBER  302128.0              0   \n",
            "2     ACEH  MAKANAN  PERKOTAAN   2016      MARET  306243.0              0   \n",
            "3     ACEH  MAKANAN  PERKOTAAN   2016  SEPTEMBER  319768.0              0   \n",
            "4     ACEH  MAKANAN  PERDESAAN   2015      MARET  297479.0              0   \n",
            "\n",
            "   daerah_encoded  gk_scaled  cluster       PC1       PC2  gk_original  \n",
            "0               2  -0.065746        5 -0.462893  1.224069     293697.0  \n",
            "1               2  -0.011441        5 -0.415091  1.225096     302128.0  \n",
            "2               2   0.015065        5 -0.391759  1.225597     306243.0  \n",
            "3               2   0.102181        5 -0.315075  1.227243     319768.0  \n",
            "4               0  -0.041386        0 -0.632508 -0.718848     297479.0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Data Splitting**"
      ],
      "metadata": {
        "id": "KkPem5eWL2UP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tahap Data Splitting bertujuan untuk memisahkan dataset menjadi dua bagian: data latih (training set) dan data uji (test set)."
      ],
      "metadata": {
        "id": "YYj1rl_JNI9Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Memeriksa Missing Values\n",
        "print(\"\\nMissing Values:\\n\", df.isnull().sum())\n",
        "\n",
        "# 3. Memisahkan Fitur dan Label\n",
        "y = df['cluster']  # Target label hasil clustering\n",
        "X = df.drop(columns=['cluster'])  # Fitur\n",
        "\n",
        "# 4. Split Data menjadi Training dan Testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 5. Normalisasi Data\n",
        "scaler = StandardScaler()\n",
        "# Hanya memilih kolom numerik\n",
        "X_train_scaled = scaler.fit_transform(X_train.select_dtypes(include=['number']))\n",
        "X_test_scaled = scaler.transform(X_test.select_dtypes(include=['number']))"
      ],
      "metadata": {
        "id": "OubAW-7ONKVj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7088111-8892-42c1-9302-8a99988159f1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Missing Values:\n",
            " provinsi          0\n",
            "jenis             0\n",
            "daerah            0\n",
            "tahun             0\n",
            "periode           0\n",
            "gk                0\n",
            "jenis_encoded     0\n",
            "daerah_encoded    0\n",
            "gk_scaled         0\n",
            "cluster           0\n",
            "PC1               0\n",
            "PC2               0\n",
            "gk_original       0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. Membangun Model Klasifikasi**\n"
      ],
      "metadata": {
        "id": "IVPbB03CMhTT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **a. Membangun Model Klasifikasi**"
      ],
      "metadata": {
        "id": "Ned1pL9zMmBK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pada tahap ini, saya menggunakan dua algoritma yang berbeda, yaitu Decision Tree dan Random Forest. Kedua algoritma ini dipilih karena memiliki keunggulan dalam menangani data dengan fitur kompleks dan menghasilkan prediksi yang akurat.\n",
        "\n",
        "Untuk membangun model ini, kami melatih kedua algoritma dengan data latih (X_train_scaled, y_train) dan melakukan prediksi terhadap data uji (X_test_scaled)."
      ],
      "metadata": {
        "id": "WAWzPOE4Nkti"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Menggunakan Decision Tree dan Random Forest\n",
        "models = {\n",
        "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
        "    'Random Forest': RandomForestClassifier(random_state=42)\n",
        "}"
      ],
      "metadata": {
        "id": "4JYxBe87NLDk"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Decision Tree**\n",
        "\n",
        "Decision Tree adalah algoritma berbasis pohon yang membagi data berdasarkan fitur tertentu hingga mencapai keputusan akhir. Setiap percabangan dalam pohon mewakili aturan keputusan yang didasarkan pada nilai fitur dalam dataset. Algoritma ini memiliki keunggulan dalam interpretabilitas yang baik dan kecepatan pelatihan yang tinggi, tetapi cenderung rentan terhadap overfitting, terutama pada dataset yang kompleks.\n",
        "\n",
        "**Random Forest**\n",
        "\n",
        "Random Forest adalah metode ensemble yang menggabungkan banyak pohon keputusan (Decision Trees) untuk meningkatkan akurasi dan mengurangi overfitting. Model ini bekerja dengan membuat beberapa pohon keputusan dari subset data yang berbeda dan menggabungkan hasil prediksinya melalui voting mayoritas (untuk klasifikasi). Dengan pendekatan ini, Random Forest lebih tahan terhadap overfitting dibandingkan Decision Tree tunggal."
      ],
      "metadata": {
        "id": "seYoHNY3XU1y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **b. Evaluasi Model Klasifikasi**"
      ],
      "metadata": {
        "id": "ergzChZFEL-O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setelah melatih model, evaluasi dilakukan dengan menghitung Accuracy, Precision, Recall, F1-Score, dan Confusion Matrix. Hasil evaluasi menunjukkan bahwa kedua model memiliki akurasi sempurna (100%) pada dataset ini, yang dapat mengindikasikan bahwa model terlalu sesuai dengan data latih (overfitting). Berikut adalah ringkasan hasil evaluasi"
      ],
      "metadata": {
        "id": "zOm68u-7NpLT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for name, model in models.items():\n",
        "    model.fit(X_train_scaled, y_train)\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "    print(f\"\\n{name} Model Performance:\")\n",
        "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"
      ],
      "metadata": {
        "id": "tMq4QAssNLip",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a5d33bf-ab74-4925-844d-25254762464e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Decision Tree Model Performance:\n",
            "Accuracy: 1.0\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       117\n",
            "           1       1.00      1.00      1.00       111\n",
            "           2       1.00      1.00      1.00       100\n",
            "           3       1.00      1.00      1.00       124\n",
            "           4       1.00      1.00      1.00       107\n",
            "           5       1.00      1.00      1.00       122\n",
            "           6       1.00      1.00      1.00       206\n",
            "           7       1.00      1.00      1.00       108\n",
            "           8       1.00      1.00      1.00        97\n",
            "\n",
            "    accuracy                           1.00      1092\n",
            "   macro avg       1.00      1.00      1.00      1092\n",
            "weighted avg       1.00      1.00      1.00      1092\n",
            "\n",
            "Confusion Matrix:\n",
            " [[117   0   0   0   0   0   0   0   0]\n",
            " [  0 111   0   0   0   0   0   0   0]\n",
            " [  0   0 100   0   0   0   0   0   0]\n",
            " [  0   0   0 124   0   0   0   0   0]\n",
            " [  0   0   0   0 107   0   0   0   0]\n",
            " [  0   0   0   0   0 122   0   0   0]\n",
            " [  0   0   0   0   0   0 206   0   0]\n",
            " [  0   0   0   0   0   0   0 108   0]\n",
            " [  0   0   0   0   0   0   0   0  97]]\n",
            "\n",
            "Random Forest Model Performance:\n",
            "Accuracy: 1.0\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       117\n",
            "           1       1.00      1.00      1.00       111\n",
            "           2       1.00      1.00      1.00       100\n",
            "           3       1.00      1.00      1.00       124\n",
            "           4       1.00      1.00      1.00       107\n",
            "           5       1.00      1.00      1.00       122\n",
            "           6       1.00      1.00      1.00       206\n",
            "           7       1.00      1.00      1.00       108\n",
            "           8       1.00      1.00      1.00        97\n",
            "\n",
            "    accuracy                           1.00      1092\n",
            "   macro avg       1.00      1.00      1.00      1092\n",
            "weighted avg       1.00      1.00      1.00      1092\n",
            "\n",
            "Confusion Matrix:\n",
            " [[117   0   0   0   0   0   0   0   0]\n",
            " [  0 111   0   0   0   0   0   0   0]\n",
            " [  0   0 100   0   0   0   0   0   0]\n",
            " [  0   0   0 124   0   0   0   0   0]\n",
            " [  0   0   0   0 107   0   0   0   0]\n",
            " [  0   0   0   0   0 122   0   0   0]\n",
            " [  0   0   0   0   0   0 206   0   0]\n",
            " [  0   0   0   0   0   0   0 108   0]\n",
            " [  0   0   0   0   0   0   0   0  97]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Decision Tree Performance\n",
        "  - Accuracy: 1.00\n",
        "  - Precision, Recall, F1-Score: Semua skor bernilai 1.00, yang berarti model memprediksi semua kelas dengan benar.\n",
        "  - Confusion Matrix: Tidak ada kesalahan klasifikasi, setiap kelas berhasil diprediksi dengan sempurna.\n",
        "2. Random Forest Performance\n",
        "  - Accuracy: 1.00\n",
        "  - Precision, Recall, F1-Score: Sama seperti Decision Tree, model ini memiliki performa sempurna.\n",
        "  - Confusion Matrix: Semua prediksi benar, tanpa kesalahan klasifikasi.\n",
        "\n",
        "Dari hasil evaluasi, kedua algoritma memiliki akurasi sempurna (1.00) dengan semua metrik evaluasi (Precision, Recall, dan F1-Score) juga bernilai 1.00. Ini berarti model berhasil memprediksi setiap kelas dengan benar tanpa kesalahan klasifikasi, seperti yang terlihat pada confusion matrix, yang tidak menunjukkan adanya kesalahan prediksi.\n",
        "\n",
        "**Kesimpulan**\n",
        "- Kedua model memiliki performa yang sama, dengan akurasi dan metrik evaluasi yang sempurna.\n",
        "- Kemungkinan overfitting sangat tinggi, karena model terlalu sempurna dalam memprediksi data uji. Hal ini bisa terjadi jika data latih dan data uji memiliki pola yang sangat mirip atau jika model terlalu kompleks untuk dataset yang digunakan.\n",
        "- Jika ingin menghindari overfitting, bisa dilakukan penyesuaian hyperparameter atau penggunaan teknik validasi silang (cross-validation) untuk memastikan model lebih generalizable terhadap data baru."
      ],
      "metadata": {
        "id": "H4_9OwrsXZlz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **c. Tuning Model Klasifikasi (Optional)**"
      ],
      "metadata": {
        "id": "ph9yIYDXEPuB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "}\n",
        "grid_search = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=5, scoring='accuracy')\n",
        "grid_search.fit(X_train_scaled, y_train)\n",
        "print(\"\\nBest Parameters:\", grid_search.best_params_)"
      ],
      "metadata": {
        "id": "winbFzb8NL95",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19a1c999-554e-426a-833b-c7d57322c2d0"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Best Parameters: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 50}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **d. Evaluasi Model Klasifikasi setelah Tuning (Optional)**"
      ],
      "metadata": {
        "id": "hE7pqlEPEYzI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = grid_search.best_estimator_\n",
        "y_pred_best = best_model.predict(X_test_scaled)\n",
        "print(\"\\nRandom Forest after Hyperparameter Tuning:\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_best))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_best))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_best))"
      ],
      "metadata": {
        "id": "HTXZRvEeNMb1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f562886-436b-4cd7-9709-507755d3242d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Random Forest after Hyperparameter Tuning:\n",
            "Accuracy: 1.0\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       117\n",
            "           1       1.00      1.00      1.00       111\n",
            "           2       1.00      1.00      1.00       100\n",
            "           3       1.00      1.00      1.00       124\n",
            "           4       1.00      1.00      1.00       107\n",
            "           5       1.00      1.00      1.00       122\n",
            "           6       1.00      1.00      1.00       206\n",
            "           7       1.00      1.00      1.00       108\n",
            "           8       1.00      1.00      1.00        97\n",
            "\n",
            "    accuracy                           1.00      1092\n",
            "   macro avg       1.00      1.00      1.00      1092\n",
            "weighted avg       1.00      1.00      1.00      1092\n",
            "\n",
            "Confusion Matrix:\n",
            " [[117   0   0   0   0   0   0   0   0]\n",
            " [  0 111   0   0   0   0   0   0   0]\n",
            " [  0   0 100   0   0   0   0   0   0]\n",
            " [  0   0   0 124   0   0   0   0   0]\n",
            " [  0   0   0   0 107   0   0   0   0]\n",
            " [  0   0   0   0   0 122   0   0   0]\n",
            " [  0   0   0   0   0   0 206   0   0]\n",
            " [  0   0   0   0   0   0   0 108   0]\n",
            " [  0   0   0   0   0   0   0   0  97]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **e. Analisis Hasil Evaluasi Model Klasifikasi**"
      ],
      "metadata": {
        "id": "ZRsOdm4uEgAW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nAnalisis Hasil Evaluasi Model:\")\n",
        "print(\"- Decision Tree mungkin mengalami overfitting karena tidak ada regularisasi.\")\n",
        "print(\"- Random Forest lebih stabil dan memiliki akurasi yang lebih tinggi.\")\n",
        "print(\"- Setelah tuning, Random Forest menunjukkan peningkatan performa dengan parameter terbaik.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9XGdcp0u35sT",
        "outputId": "7572e7da-7aa8-4470-bc47-2e1a98c7b1d9"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Analisis Hasil Evaluasi Model:\n",
            "- Decision Tree mungkin mengalami overfitting karena tidak ada regularisasi.\n",
            "- Random Forest lebih stabil dan memiliki akurasi yang lebih tinggi.\n",
            "- Setelah tuning, Random Forest menunjukkan peningkatan performa dengan parameter terbaik.\n"
          ]
        }
      ]
    }
  ]
}